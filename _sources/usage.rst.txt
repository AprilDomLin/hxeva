.. hxeva documentation file, created by fang linwanghao
   sphinx-quickstart on Thu Dec  1 12:44:57 2022.
   You can adapt this file completely to your liking, but it should at least
   contain the root `toctree` directive.

使用示例
===========================

业务使用示例
---------------------------

业务需求和评估逻辑与hxeva产品检验评估参考类相同
``````````````````````````````````````````````````````````````````````````````````

以QPF格点检验为例，首先实例化相应产品类，修改业务参数后调用评估主进程main::

    # python file : qpf.py

    from datetime import timedelta
    from hxeva import RadaFcstGrid

    # 传入基本参数，检验区域可通过修改extend经纬度范围完成限制
    model = RadaFcstGrid(name="RADA_PRE_HOR_03H_GRID", extend=dict(slat=18.91, slon=108.43, elat=26.88, elon=118.83),
                         shape=(798, 1041))

    # 真值数据参数 (以GIRB2 格式的 CMPAS为例)
    truth_file = {"file": "~/data/CMPAS_GRIB/%Y/%Y%m/%Y%m%d/*-%Y%m%d%H.GRB2",       # 数据路径匹配规则
                  "timezone": "CTS",                                                # 数据时制
                  "name_Lat": "Lat",                                                # 数据纬度变量名称
                  "name_Lon": "Lon",                                                # 数据经度变量名称
                  }

    # 待评估数据参数
    test_file = {"file": "~/product/FCST/SZW_1000M/F_RADA_FCST_03H_DL/%Y%m%d/%Y%m%d%H%M_%Y%m%d%H%M.nc",       # 数据路径匹配规则
                 "timezone": "UTC",                                                                           # 数据时制
                 "name_Lat": "Lat",                                                                           # 数据纬度变量名称
                 "name_Lon": "Lon",                                                                           # 数据经度变量名称
                 }

    # 检验配置参数
    qpf_config = {"truth_file": truth_file,                                         # 真值数据信息
                  "test_file": test_file,                                           # 测试数据信息
                  "save": "~/product/CHECK/RADA_PRE_HOR_03H_GRID/%Y%m%d/%Y%m%d%H",  # 保存路径规则
                  "timefcst": [timedelta(hours=hour) for hour in range(2, 0, -1)],  # 预报时效列表
                  "key": "PRE_1h",                                                  # 变量关键字名称
                  "threshold": [0, 0.1, 2.5, 8.0, 16.0, 150],                       # 评分检验阈值表
                  "code": "RADA_PRE_HOR_03H_STATION",                               # 保存结果，对应type字段
                  "area": "Guangdong_SZW_1000M",                                    # 检验产品区域范围，对应 area字段
                  }
    # 修改业务化参数
    # tag_time=None : 每次启动时，自动获取服务器的当前时间
    # fmt="%Y%m%d%H" : 日志保存格式，例如为 2023013018.log
    # days=3 : 仅保存3天以内的日志
    # sleep_time=10 : 当出现意外错误，每次循环等待10s，以排除文件延迟到达波动的情况
    # delay=15 : 延迟15min检验，例如18时15分开始检验18时起报的产品，主要解决实况资料和产品数据的延迟情况(根据实际情况修改). !!!若业务时效需求较高，则不能用此方法!!!
    model.main(tag_time=None, fmt="%Y%m%d%H", days=3, sleep_time=10, delay=timedelta(minutes=15), **qpf_config)

将.py文件加入crontab定时任务即可。



独特业务需求，与参考类逻辑不同，但主题业务逻辑相同
``````````````````````````````````````````````````````````````````````````````````

仍以CREF格点检验为例，首先继承BaseProdEvaluate，根据业务需求修改evaluate方法，然后调用评估主进程main::

    # python file : cref.py

    from abc import ABC
    from datetime import timedelta
    from pathlib import Path

    import numpy as np
    import pandas as pd

    from hxeva import BaseProdEvaluate, DataReader, Score, Stats, Space, Default, read_boundary


    # 传入基本参数，检验区域可通过修改extend经纬度范围完成限制
    class CREFNew(BaseProdEvaluate, ABC):
        def __init__(self, name="RADA_PRE_CREF_03H_GRID", log_root="./logs", extend=None, shape=None, max_counter=10):
            super(CREFNew, self).__init__(name=name, log_root=log_root, max_counter=max_counter, shape=shape)
            self.extend = extend

        def evaluate(self, tag_time, truth_file, test_file, **kwargs):
            # Keyword Args
            save = kwargs.pop("save")
            timefcst = kwargs.pop("timefcst")
            key = kwargs.get("key", "PRE_1h")
            threshold = kwargs.get("threshold", [0, 0.1, 2.5, 8.0, 16.0, 150])
            loc = kwargs.get("location", None)
            code = kwargs.get("code", "RADA_PRE_HOR_03H_GRID")
            area = kwargs.get("area", None)

            #  读取 truth 数据 >>> UTC
            path = Path(DataReader.catch(time=self.transform_time(tag_time, timezone=truth_file["timezone"]),
                                         lead_time=None, file=truth_file["file"]))
            if not self._path_judge(path, "GRID(Truth)"):
                return False
            truth = DataReader.load(path, vnames=[key], extend=loc,
                                    name_lat=truth_file["name_Lat"], name_lon=truth_file["name_Lon"])

            for lead_time in timefcst:
                rep_time = tag_time - lead_time
                #  读取 test 数据 >>> UTC
                path = Path(DataReader.catch(time=self.transform_time(rep_time, timezone=test_file["timezone"]),
                                             lead_time=lead_time, file=test_file["file"]))
                if not self._path_judge(path, "Test"):
                    return False
                test = DataReader.load(path, vnames=[key], extend=loc,
                                       name_lat=test_file["name_Lat"], name_lon=test_file["name_Lon"])

                # 实况、产品与行政边界格点匹配
                if key not in truth:
                    truth[key] = np.ones_like(border_code) * np.nan
                if key not in test:
                    test[key] = np.ones_like(border_code) * np.nan

                # SAL
                sal_res = pd.DataFrame(columns=["stime", "ftime", "area", "type", "method", "S", "A", "L"])
                sal_res.loc[0, "stime"] = rep_time.strftime("%Y%m%d%H%M")
                sal_res.loc[0, "ftime"] = tag_time.strftime("%Y%m%d%H%M")
                sal_res.loc[0, "area"] = area
                sal_res.loc[0, "type"] = code
                sal_res.loc[0, "method"] = "SAL"

                # 评估
                exist_flag = np.where((threshold[0] <= truth[key]) & (truth[key] <= threshold[-1]) &
                                      (threshold[0] <= test[key]) & (test[key] <= threshold[-1]), True, False)
                tmp = Space.SAL(truth[key], test[key], exist_flag=exist_flag, threshold=[threshold[1], threshold[-1]],
                                min_points=25)
                sal_res.loc[0, "S"] = tmp["S"]
                sal_res.loc[0, "A"] = tmp["A"]
                sal_res.loc[0, "L"] = tmp["L"]

                ts_res = pd.DataFrame(columns=["stime", "ftime", "area", "type", "method"])
                stats_res = pd.DataFrame(columns=["stime", "ftime", "area", "type", "method"])

                for col in border_list.itertuples():
                    qx_code = getattr(col, "qxCode")
                    if qx_code != "-1":
                        exist_flag = np.where(border_code == qx_code, True, False)
                        qx_name = getattr(col, "dsName") + getattr(col, "qxName")
                    else:
                        exist_flag = np.ones_like(border_code).astype(np.bool_)
                        qx_name = "全区平均"

                    # 初始化检验结果
                    # TS 评分
                    index = len(ts_res)
                    ts_res.loc[index, "stime"] = rep_time.strftime("%Y%m%d%H%M")
                    ts_res.loc[index, "ftime"] = tag_time.strftime("%Y%m%d%H%M")
                    ts_res.loc[index, "qxName"] = qx_name
                    ts_res.loc[index, "area"] = area
                    ts_res.loc[index, "type"] = code
                    ts_res.loc[index, "method"] = "TS"

                    # 评估
                    truth_c = Score.transform(data=truth[key], threshold=threshold)
                    test_c = Score.transform(data=test[key], threshold=threshold)
                    for lvl, name in Default.RainLevel.items():
                        tables = Score.classify(truth=truth_c, test=test_c, exist_flag=exist_flag, level=int(lvl),
                                                method="binary", window_size=None)
                        for s in ["TS", "PO", "FAR"]:
                            tmp = getattr(Score, s.lower())(tables)
                            ts_res.loc[index, f"{name}_{s}"] = 999 if np.isnan(tmp) else round(float(tmp), 4)

                    # 统计误差
                    index = len(stats_res)
                    stats_res.loc[index, "stime"] = rep_time.strftime("%Y%m%d%H%M")
                    stats_res.loc[index, "ftime"] = tag_time.strftime("%Y%m%d%H%M")
                    stats_res.loc[index, "qxName"] = qx_name
                    stats_res.loc[index, "area"] = area
                    stats_res.loc[index, "type"] = code
                    stats_res.loc[index, "method"] = "STATISTIC"

                    # 评估
                    tmp = Stats.stats(truth=truth[key], test=test[key], exist_flag=exist_flag, amin=threshold[0],
                                      amax=threshold[-1], names=["MBR", "MAE", "CC", "NMAE", "NME", "NSE"])
                    for name in ["MBR", "MAE", "CC", "NMAE", "NME", "NSE"]:
                        stats_res.loc[index, name] = 999 if np.isnan(tmp[name]) else tmp[name]

                # 保存评估结果
                path = Path(DataReader.merge_file(time=rep_time, lead_time=lead_time, file=save["ts"]))
                Path(path).parent.mkdir(parents=True, exist_ok=True)
                ts_res.to_json(path, orient="records", force_ascii=False, lines=True)
                path = Path(DataReader.merge_file(time=rep_time, lead_time=lead_time, file=save["stats"]))
                Path(path).parent.mkdir(parents=True, exist_ok=True)
                stats_res.to_json(path, orient="records", force_ascii=False, lines=True)
                path = Path(DataReader.merge_file(time=rep_time, lead_time=lead_time, file=save["sal"]))
                Path(path).parent.mkdir(parents=True, exist_ok=True)
                sal_res.to_json(path, orient="records", force_ascii=False, lines=True)
            return True


    def main():
        model = CREFNew(name="RADA_CREF_03H_GRID", extend=dict(slat=18.91, slon=108.43, elat=26.88, elon=118.83),
                        shape=(798, 1041))

        # 真值数据参数
        truth_file = {"file": "~/product/OBS/SZW_1000M/O_RADA_PRODUCT/%Y%m%d/%Y%m%d%H%M_%Y%m%d%H%M.nc",  # 数据路径匹配规则
                      "timezone": "UTC",  # 数据时制
                      "name_Lat": "Lat",  # 数据纬度变量名称
                      "name_Lon": "Lon",  # 数据经度变量名称
                      }

        # 待评估数据参数
        test_file = {"file": "~/product/FCST/SZW_1000M/F_RADA_FCST_03H_DL/%Y%m%d/%Y%m%d%H%M_%Y%m%d%H%M.nc",  # 数据路径匹配规则
                     "timezone": "UTC",  # 数据时制
                     "name_Lat": "Lat",  # 数据纬度变量名称
                     "name_Lon": "Lon",  # 数据经度变量名称
                     }

        # 检验配置参数
        cref_config = {"truth_file": test_file,
                       "test_file": test_file,
                       "file": "~/product/CHECK/RADA_CREF_03H_GRID/%Y%m%d/%Y%m%d%H",   # 保存路径规则
                       "timefcst": [timedelta(minutes=m) for m in range(120, 0, -6)],  # 预报时效列表
                       "key": "CREF"  # 变量关键字名称
                       }
        # 修改业务化参数
        model.main(tag_time=None, fmt="%Y%m%d%H", days=3, sleep_time=10, delay=timedelta(minutes=15), **cref_config)


    if __name__ == "__main__":
        _tmp = read_boundary([f"./scr/Guangdong_info.nc", f"./scr/Guangdong_info.txt"])
        border_code = _tmp["BORDERCODE"]
        border_list = _tmp["BORDERLIST"]
        main()

将.py文件加入crontab定时任务即可。

CMAE接口示例
---------------------------

【暂无】


算法人员使用示例
---------------------------
以算法人员常用np.ndarray 数据格式作为评估检验的输入使用示例，真值采用ERA5数据，预报产品采用模式预报数据进行评估，
以模拟“模式订正”算法研发时，针对产品的快速评估检验。


数据读取
`````````````````````````````````````````````````
读取实况数据(做为truth)和预报数据(做为test)::

    from netCDF4 import Dataset

    path = "../scr/data/O_ERA5_SURF_025KM_2022052612.nc"
    tmp = Dataset(path)
    obs = tmp.variables["pre_3h"][::2, ::2] * 1000

    path = "../scr/data/F_T1279_SURF_050KM_NAFP_2022052500_2022052612.nc"
    tmp = Dataset(path)
    fcst = tmp.variables["pre_3h"][:] * 1000

评分检验
`````````````````````````````````````````````````
::

    from hxeva import Score

    # 直接调用Score.calc方法进行评分计算
    Score.calc(truth=obs, test=fcst, threshold=[0, 0.1, 3, 10, 20, 50, 70, 300],
           names=["TS", "FAR", "PO", "POD", "acc"])

输出结果::

    level	TS	FAR	PO	POD	acc
    ≥ 0	        1.0000	0.0000	0.0000	1.0000	1.0000
    ≥ 0.1	0.5300	0.3403	0.2706	0.7294	0.7820
    ≥ 3	        0.1166	0.7980	0.7838	0.2162	0.9389
    ≥ 10	0.0364	0.8667	0.9524	0.0476	0.9965
    ≥ 20	0.0000	1.0000	1.0000	0.0000	0.9991
    ≥ 50	9999.0000	9999.0000	9999.0000	9999.0000	1.0000
    ≥ 70	9999.0000	9999.0000	9999.0000	9999.0000	1.0000
    >>> Scores Calculated Done! Result has been saved in "./scores.csv"!

误差检验
`````````````````````````````````````````````````
::

    from hxeva import Stats

    # 直接调用Stats.calc方法进行评分计算
    Stats.calc(truth=obs, test=fcst, amin=0, amax=300, names=["RMSE", "MAE", "MBE", "CC", "MAE", "MAPE"])

输出结果::

    RMSE:  1.5448
    MAE:  0.5567
    MBE:  0.0134
    CC:  0.2906
    MAE:  0.5567
    MAPE:  1.2067
    >>>Statistics Calculated Done! Result has been saved in "./stats.csv"!

SAL空间检验
`````````````````````````````````````````````````
::

    from hxeva import Space

    # 直接调用Space.calc方法进行评分计算
    Space.calc(truth=obs, test=fcst, threshold=[0.1, 999], min_points=15)

输出结果::

    S:  0.6422
    A: -0.0806
    L:  0.0527
    >>>SAL Calculated Done! Result has been saved in "./space.csv"!

